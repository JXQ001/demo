分布式缓存
1.项目中缓存的使用场景
	高性能，查询商品信息，商品在上架后在短时间一般不会改变，这个时候可以将数据加入缓存，提升用户查询的速度（提升用户体验）
2.为什么使用缓存
	高性能，高并发（未使用）
3.使用缓存后有什么问题
	系统复杂性，可用性，一致性
4.如何保证数据库和缓存的读写一致,按Cache Aside pattern原则
	①读的时候先读取缓存中的数据，缓存不存在在读取数据库中，然后将读取的数据放入缓存并响应请求
	②写的时候先删除缓存中的数据，然后更新数据库

dubbo
1. 支持的协议？
	①默认dubbo协议，单一长连接，异步NIO,hessian序列化
	②rmi、http、redis、
2.负载均衡策略？
	①random loadbalance	随机调用，可以设置权重，权重越高分配请求越多
	②roundrobin loadbalance	轮询，也根据机器的配置可以设置权重
	③leastactive loadbalance 自动感知，给性能差的机器分配少的请求
	④consistant hash loadbalance 一致性hash,将相同参数的请求分发到同一个机器上 
3.集群容错
	①fallover cluster，默认的容错，失败自动重试，常用于读操作
	②failfast cluster，一次失败立即失效，常用于写操作
	③failsafe cluster，出现异常忽略，记录日志
	④failback cluster，失败后定时重试，记录日志
	⑤forKing cluster，并行的调用多个provider，只要一个成功就返回
	⑥broadcast cluster，逐个调用所有的provider
4.spi思想,service provicer interface
5.幂等性问题如何保证
	①在Redis中做标识记录
	②在数据库中使用唯一索引
6.如何保证顺序性？使用内存队列处理	

redis
0.数据类型
	①string（k-v键值对）②list(文字评论，微博粉丝)、hash(存对象)、set（无序，可去重）、sorted set

1.内存淘汰机制
    ①从已设置过期时间的数据集中淘汰(server.db[i].expires)
        随机过期数据(volatile-random)
        最少使用的数据(volatile-ttl)
        将要过期的数据(volatile-lru)
    ②当内存不足以容纳写入数据时，在键空间中，移出最近最少使用的key(allkeys-lru),最常用
    ③从数据集(server.db[i].dict)中随机任意选择数据淘汰（allkeys-random）
    ④禁止驱逐数据（no-eviction），内存不足写入报错，不使用
2.持久化
    ①快照（RDB）,默认的持久化方式，save 900 1 900秒后1个key变化会触发
    ②追加（AOF），默认不开启，通过appendonly yes 开启，
    ③redis4.0之后支持RDB和AOF混合持久化，默认关闭，通过aof-use-rdb-preamble开启
3.缓存雪崩和缓存穿透问题
    ①缓存雪崩，缓存同一时间失效，请求落到数据库，导致数据库短时间承受大量请求崩掉。
        解决：
            1.事前，保证redis集群的高可用，选择合适的内存淘汰策略
            2.事中，本职ehcache+限流组件缓存
            3.事后，利用持久化机制保存的数据恢复缓存
    ②缓存穿透，用户请求缓存中不存在的数据，导致请求落在数据库上，造成数据库短时间承受大量数据崩掉。
            解决：
            1.使用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被拦截
            2.粗暴的方法，将查询为空（不管数据不存在，系统故障）的数据也进行缓存，设置较短的过期时间
4.集群的方式
    ①主从复制
    ②哨兵模式
    ③Cluster集群
    
线程池
1.七大参数
	①corePoolSize,线程池中常驻的核心线程数
	②maximumPoolSize,线程池的最大线程数
	③keepAliveTime,当前线程池中的线程数超过了核心线程数，当空闲时间到达keepAliveTime值时，多余的空闲线程会被销毁，直到剩下corePoolSize的线程数
	④unit,keepAliveTime的单位
	⑤workQueue,任务队列，被提交但未被执行的任务
	⑥threadFactory,创建线程的工厂，一般默认
	⑦handler,拒绝策略，当达到线程池最大线程数并且任务队列满了之后触发的拒绝请求执行的runnable的策略

消息队列
1.为什么要使用消息队列？
	①解耦，多个系统耦合在一起，维护成本高，使用pub/sub发布订阅来解耦
	②异步，用户发送一个请求到一个系统，但这个系统要调用其他系统，耗时较大，会延时，可以把消息发到mq中
	③肖峰，某个时间段用户访问量很大，系统直接链接数据库，会让数据库崩掉，可以先把数据发到mq	
2.消息队列有什么缺点？
	①系统的可用性降低，mq故障后发送方无法发送消息，消费方无法消费消息
	②系统的复杂性提高了，消息丢失、重复消费、无序、积压	
	③一致性问题，事务如何保证
3.如何保证消息队列的高可用？
	①集群
	②
	③	
4.如何保证消息队列的幂等性（重复消费），每次消费的时候先去验证是否消费了本条数据，消费过直接丢弃	
	①要求生产者每次发送消息的时候添加全局唯一ID,消费者可以先去数据库中查询，存在则不插入
	②每次消费完了将数据写到redis一份，下次再消费之前先去Redis中查询，存在则不插入
	③在数据库中使用唯一索引  
5.如何处理消息传输的丢失？（生产者发送了，消费者没消费）
	①基于事务（rabbitMQ），会导致阻塞，降低吞吐量
	②使用confirm模式，异步回调，生产者提供回调接口给MQ
	③开启rabbitMQ持久化
	④关闭消费者的（AutoAck）自动确认消费，改为手动确认消息已消费    
    ⑤kafka设置同步成功才返回成功给消费者，生产者对于发送失败的进行重试
6.如何保证消息的有序性？
	①给需要保证顺序的消息放在一个queue中让消费者去消费
	②消费者多线程处理消息的无序性，开启多线程之前使用内存队列去分发
7.如何处理消息大量消息积压？	
	①mq磁盘充足情况下，消费者故障了，将消费者消费的消息不要入库，直接写到新的队列中，部署多台临时消费者从新的队列中去快速消费
	②mq磁盘满了，消费者直接消费，不入库，通过定时任务将那些消息重新发送给mq
	③消息设置了过期时间（尽量不设置），还没有消费就过期了，使用定时任务处理
8.如果让你设计一个MQ,如何做？
	①分布式可扩容
	②高可用，不要随便挂掉
	③持久化，不要丢失消息

MySQL
1.主从复制，一主多从
2.主从延迟，主库binlog->从库relaylog->数据，插入更新后立马查询，查询不到问题（重试查询）
3.主从复制数据丢失，从库还没同步完，主库挂掉了，使用半同步复制解决
4.并行复制，多库并发重放relay日志，缓解主从延迟
5.分库分表
	①数据迁移问题，挂公告停机迁移
	②不停机，旧库和新库双写
	③扩容问题

    